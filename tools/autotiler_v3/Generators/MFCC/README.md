# Autotiler MFCC

This folder contains the function to generate and run MFCC on GAP. The reference algorithm cna be found [here](http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/). The [tensorflow](https://www.tensorflow.org/api_docs/python/tf/signal/mfccs_from_log_mel_spectrograms) implementation is also supported. Setting _USE_TF_FB=True_ in the GenLUT script will generate the tensorflow mel filterbank.

## Algorithm:

	- (optional) PreEmphasis Y[n] = X[n] - PREEMP_FACTOR\*X[n-1]
	- (optional) Windowing  (default: Hanning)
	- FFT (default: radix2)
	- Spectrogram (default: power)
	- MelFilterBank
	- (optional) Natural Logarithm or 10*log10(x)
	- (optional) DCT
	- (optional) Lifter


## Usage

In MfccModel.c you will find 2 examples of code generation for the MFCC execution over N_FRAME of size FRAME_SIZE stacked together with stride FRAME_STEP and over a single frame. For more details about the Autotiler MFCC API look in MfccGenerator.h.

The MFCC parameters are passed in the MfccModel.mk. According to them, the MFCC_params.h will be generated by the GenLUT.py script. The GenLUT.py script will generate for you the look up tables necessary for the several steps of the preprocessing function.

Several implementations are available, in particular the user can specify the desired implementation by changing the Generators arguments:

	- N_FRAMES: number of frames to compute the MFCC
	- FRAME_SIZE: size in sample of a single frame
	- FRAME_STEP: stride in sample between two consecutive frames
	- N_FFT: The number of FFT bins must be specified by the user (must be power of 2 and > than FRAME_SIZE)
	- MFCC_COEFF_CNT: number of elements of the Mel filterbank sparse matrix generated by GenLUT.py
	- N_DCT: number of DCT bins. If less than MFCC_COEFF_CNT only the first N_DCT samples of logmel will be considered. If 0 dct will not be computed
	- PREEMP_FACTOR (float): apply a PreEmphasis to the input frame: Y[n] = X[n] - PREEMP_FACTOR\*X[n-1]. Put 0 if this part is not necessary.
	- USE_RADIX_4: if N_FFT = 4^k radix 4 fft implementation can be used specifying the USE_RADIX_4=1
	- USE_POWER: if 1 computes the power spectrogram of the FFT output (|STFT|^2), otherwise computes the |STFT|. The second approach requires float emulated functions (sqrt), hence has a significative drop in performance
	- DATA_TYPE: 
		- 0: fixed point 16 bits implementation: default
		- 1: fixed point 32 bits implementation (NOTE: to use this functionality you will need to define HIGH_PREC_FFT at compilation time to get the rights functions from Autotiler basic kernels)
		- 2: float16 implementation (only available in gap9)
		- 3: float32 implementation
	- MFCC_BANK_CNT: number of mel filters used to calculate the mel spectrogram
	- OutMelFilterbank: if 1 no logarithm and dct will be applied.

In the fixed point implementation the quantization strategy will be as follow:

	- Apply a Window to the input, can be changed in the GenLUT script (default: HANNING window, a fixed point version of numpy function of dimension FRAME_SIZE will be generated in the LUT file)
	- OutMelspectrogram if set will generate the function to compute the Mel Filterbank output only. In this case if a fixed point implementation is used the output will be an array of _unsigned int_ in Q12.20 format.
	- An optional DCT can be applied after the log, N_DCT must be specified by the user. The default DCT algorithm is the [type II](https://docs.scipy.org/doc/scipy/reference/generated/scipy.fftpack.dct.html) with fixed point arithmetic and without any normalization. The output in this case will be an array of _short int_ in Q(10 - _Norm_), with _Norm_ specified by the user in the function call (empyrically found _Norm_=5 provides good results).
	- If N_DCT=0 the DCT function will not be generated and the output will be the LogMel spectrogram. In this case the output will be an array of _short int_ in Q(16 -_Norm_) quantization format, with _Norm_ specified by the user in the function call (empyrically found _Norm_=5 provides good results).
	- A lifter coeff can be applied after the DCT if present

In the following a reference code from tensorflow to compute the steps in the same way they are done by our algorithm:

```python
import tensorflow as tf # Tested with Tensorflow 2.X

tf_data = tf.cast(data, tf.float32)
tf_stfts = tf.signal.stft(tf_data, frame_length=FRAME_SIZE, frame_step=FRAME_STEP, fft_length=N_FFT)
tf_spectrograms = tf.abs(tf_stfts)
if power:
    tf_spectrograms = tf_spectrograms ** 2

num_spectrogram_bins = tf_stfts.shape[-1]
linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(N_MELS, num_spectrogram_bins, samplerate, FMIN, FMAX)

tf_spectrograms = tf.cast(tf_spectrograms, tf.float32)
tf_mel_spectrograms = tf.tensordot(tf_spectrograms, linear_to_mel_weight_matrix, 1)

tf_log_mel = tf.math.log(tf_mel_spectrograms + 1e-6)

# To match exactly this result you will need to normalize the output from gap with a factor of 0.5*sqrt(2/N_DCT)
tf_mfccs = tf.signal.mfccs_from_log_mel_spectrograms(tf_log_mel[:, :N_DCT])[..., :N_DCT]
if tf.__version__.startswith("1"):
    tf_mfccs = tf.Session().run(tf_mfccs)
```

## Mel Filter

The GenLUT.py script has several option to choose the mel filterbank to generate. 3 implementation are available (parameters must be specified in the GenLUT.py arguments when calling the script):
	
	- default: mel filter generated as described at [here](https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html)
	- --use_tf_mfcc: ```tf.signal.linear_to_mel_weight_matrix(N_MELS, num_spectrogram_bins, samplerate, FMIN, FMAX)```
	- --use_librosa: ```librosa.filters.mel(samplerate, N_FFT, N_MELS, fmin, fmax, norm=librosa_mel_norm)```

## STFT and ISTFT

In the same way also STFT and inverse STFT can be generated. You can look at the APIs in MfccGenerator.h

## Run example

To generate the code with the default settings in MfccModel.mk:
	make clean_model mfcc_model 

To run the generated code:
	make clean all run

## WIP

Support in nntool of code generation for mfcc and stft/istft
